version: '3'
services:

  # test airflow service with SQLite backend to make it MVP (not for production)
  airflow:
    build:
      context: .
      dockerfile: ./docker/Dockerfile.airflow
    container_name: airflow
    ports:
      - 8080:8080
    volumes:
      - airflowdata:/tmp/airflow/artifacts/
      - ./mlflows:/mlflow/artifacts
      - ./dags:/opt/airflow/dags
    networks:
      - frontend
      - backend
    env_file:
      - ./env_files/compose.env
      - ./env_files/secrets.env
    command: standalone

  # mlfow server with postgresql db backend
  mlflow:
    build:
      context: .
      dockerfile: ./docker/Dockerfile.mlflow
    container_name: mlflow
    ports:
      - 5000:5000
    volumes:
      - ./mlflows:/mlflow/artifacts
    depends_on:
      - postgresql
    networks:
      - frontend
      - backend
    env_file:
      - ./env_files/compose.env
      - ./env_files/secrets.env
    command: /tmp/start_mlflow.sh

  # db backend for mlflow
  postgresql:
    image: postgres:10.5
    container_name: postgresql
    expose:
      - "5432"
    env_file:
      - ./env_files/compose.env
      - ./env_files/secrets.env
    hostname: postgresql
    shm_size: 256mb
    volumes:
      - ./dbs:/var/lib/postgresql/data
    networks:
      - backend
    restart: always
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 5s
      retries: 5

networks:
  frontend:
    driver: bridge
  backend:
    driver: bridge

volumes:
    airflowdata:


# additional keys
# MLFLOW_S3_ENDPOINT_URL=http://mlflow-artifact-store:9000
# AWS_ACCESS_KEY=AKIA3FLD32HPRN22NJQ7
# AWS_SECRET_ACCESS_KEY=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
# MINIO_ROOT_USER=minio
# MINIO_ROOT_PASSWORD=miniostorage
# MINIO_ENCRYPTION=auto