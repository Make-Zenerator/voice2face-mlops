{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"http://localhost:8080/predictions/voice2face\"\n",
    "\n",
    "def query(payload):\n",
    "\tresponse = requests.post(API_URL, json=payload)\n",
    "\treturn response.json()\n",
    "\n",
    "output = query({\n",
    "    \"input\" : \n",
    "})\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status\": \"Healthy\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl http://localhost:8080/ping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m res \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(URL, json\u001b[38;5;241m=\u001b[39mdata)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(res\u001b[38;5;241m.\u001b[39mjson())\n\u001b[0;32m---> 20\u001b[0m img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutputs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m],dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m512\u001b[39m,\u001b[38;5;241m512\u001b[39m,\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     21\u001b[0m img\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# np.asarray(res.json()['outputs'][0]['data']).shape\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import requests                                                \n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "URL = \"http://localhost:8080/predictions/voice2face\"\n",
    "data = {                                    \n",
    "        \"name\": \"hug_voicetoface\",\n",
    "        \"inputs\": [             \n",
    "            {   \n",
    "                    \"name\": \"prompt\",\n",
    "                    \"shape\": [1], \n",
    "                    \"datatype\": \"BYTES\",\n",
    "                    \"data\": [\"A cinematic clear shot of a 20-year-old male\"]\n",
    "            }\n",
    "        ]\n",
    "}                    \n",
    "res = requests.post(URL, json=data)\n",
    "print(res.json())\n",
    "\n",
    "img = np.asarray(res.json()['outputs'][0]['data']).reshape(512,512,3)\n",
    "img\n",
    "# np.asarray(res.json()['outputs'][0]['data']).shape\n",
    "Image.fromarray(img).save(\"output1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
